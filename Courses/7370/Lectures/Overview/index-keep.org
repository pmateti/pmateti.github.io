# -*- mode: org -*-
#+Date: 2020-01-01
#+TITLE: DistrComp  Course Overview
#+AUTHOR: Prabhaker Mateti
#+DESCRIPTION: Mateti's Distributed Computing
#+BIND: org-html-preamble-format (("en" "%d | <a href=\"../../\">../../</a>"))
#+BIND: org-html-postamble-format (("en" "<hr size=1>Copyright &copy; 2020 &bull; <a href=mailto:pmateti@iiitd.ac.in>pmateti@iiitd.ac.in</a> &bull; %d"))
#+HTML_LINK_HOME: ../../Top/index.html
#+HTML_LINK_UP: ../
#+HTML_HEAD: <style> P, LI {text-align: justify} code {color: brown;} @media screen {BODY {margin: 10%} }</style>
#+STARTUP:showeverything
#+OPTIONS: toc:1

* Course Overview

1. WSU CEG7370 [[https://cecs.wright.edu/~pmateti/Courses/7370/Top/][Distributed Computing]] Course Home Page

2. [[./syllabus.html][Syllabus]] of the IIIT-Delhi version of this course

3. [[../Projects/7370projects.html][Projects]]

4. Two exams. Most likely [[../../Exams/index.html][take-home]].  But, without searching the web or
   whatever for answers.

5. No graded homework.  Implies that you will work on
   various things on your own and discuss.
6. [[https://piazza.com/wright/spring2020/ceg7370/home][Piazza]] is our discussion platform.


* Three Sample Lectures

1. These are samples.  We will re-visit these topics for a full
   exploration.

1. Distributed Computing Technology
2. Semantics of SemiColon, Parallel-Bar, and Vertical Bar
3. Mathematics of Concurrency

** Distributed Computing Technology

1. Peer-to-peer computing vs Client-Server computing
1. Message passing v shared variables
1. RPC (Remote Procedure Call), RMI (Remote Method Invocation)
1. [[../Projects/rpc-diag-tikz.pdf]]  RPC/RMI Architecture
1. [[../Projects/rpc-marshalling-tikz.pdf]] Marshalling/Serializing of Data Structures


** Semantics of SemiColon, Parallel-Bar, and Vertical Bar

1. Meaning of
   1. =S1 ;; S2= 
   2. =S1 || S2=
   3. =S1 [] S2=

2. Consider p60 of Andrew's Concurrent Programming [now using single
   semicolon]
   #+begin_src SR
   { 
     y := 0; z := 0;
     co x := y + z 
     || {y := 1; z := 2}
     oc
   }
#+end_src

3. Can x be 0, 1, 2 or 3 at the end of the above code?
1. We will have a lecture on [[../Fundas/semicolon-par-fat-bars.org]]

** Mathematics of Concurrency
1. [[../FormalMethods/assertions-slides.html]] This page is about
   assertions, without concurrency related issues.
1. [[../FormalMethods/math-of-concurrency.html]] Mathematics of Shared
   Variables.  This page is about shared variable concurrency issues,
   using mathematical logic.
1. [[../FormalMethods/temporal-logic-slides.html]] Classical mathematical
   logic deals with timeless statements.  Classical logic cannot
   express: "This basket will have 10 red balls."  Interesting
   statements about processes depend on time.


* Concurrency Fundamentals

â€‹
1. We are picky about our terms.
1. Ex: "Process"
   1. All the following are conceptually the same: process, thread,
      task, job, ...
   2. On a given platform (e.g., Linux): process v thread v ... are different
   1. By def: a single process is sequential

1. Muliprocess v Multiprocessor v Multi-core: Same? Similar?

** Concurrency Fundamentals #2: Non-Determinacy

1. Ex: Consider the simple assignment statement x := 3 [] 7 (Note
   the fat-bar)
   1. What is the value of x?
   2. Either 3 or 7; guaranteed nothing else.
   3. But which? When is it 3? When is it 7? 
   4. Code following the line above, better be prepared for either
      value.
2. Computation C is non-determinant: Each time we run, the result of C
   may
   change "for no good reason."  Why? Because "non-determinacy" is
   baked in.

** Concurrency Fundamentals #3: Meta Terminology

1. Fundamentals v Principles v Foundations
1. Concurrency Fundamentals constitute the core of this course.
1. Until the last week of this course, we will use "concurrency" as a
   term covering all of networked-, parallel-, distributed- computing.


* Survey of Prerequisites

1. [[../Overview/survey.org][Survey of Prerequisites]] 
1. We will try to fill you in on most of the prerequisites. The survey
   is for that purpose. In some ways it may be better that you have
   not heard of some of these things.
1. Post on Piazza this survey answered in detail.


* Home Work

1. Learn the Mine Sweeper game.  Imagine each cell is a computer
   system.  A cell talks to others only through message passing.  How
   do we program it?
1. Study today's lecture.
1. Enroll and post on Piazza the [[../Overview/survey.org][Survey of Prerequisites]] answered in
   some detail.

* References

Reading list for this course is a transitive closure starting from the
ones linked on the course home page. Items marked as Require Reading
are sources for exam questions. Other items do enhance your
understanding, but, if you are not aiming for an A, you may skip.

** References #1

1. I will list specific chapters from Recommended Books later.

1. Gregory R. Andrews, Concurrent Programming: Principles and
   Practice, Benjamin/Cummings, 1991.  {pm: This *is* our text book.
   A classic.  We will do Chapters 1 and 2 much later in our course. }

1. Also see his revision of the above book.
   [[./andrews-multithreaded-toc.org]] {We will note Excluded chapters and
   sections.  We do cover things not included in this book.}

** References #2

1. M. Ben-Ari, Principles of Concurrent and Distributed Programming,
   Addison-Wesley/Pearson, 2006.  {Another classic.}

1. George Coulouris, Jean Dollimore, Tim Kindberg, and Gordon Blair,
   Distributed Systems: Concepts and Design, 2011.  {Systems as
   opposed to principles, and foundations.}

1. Other references listed in lectures.


# Local variables:
# after-save-hook: org-html-export-to-html
# end:
