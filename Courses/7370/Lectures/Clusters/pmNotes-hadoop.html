<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2019-12-09 Mon 08:29 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Hadoop and Alternatives</title>
<meta name="generator" content="Org mode" />
<meta name="author" content="Prabhaker Mateti" />
<meta name="description" content="CEG7370 Distributed Computing"
 />
<style type="text/css">
 <!--/*--><![CDATA[/*><!--*/
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #ccc;
    box-shadow: 3px 3px 3px #eee;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: visible;
    padding-top: 1.2em;
  }
  pre.src:before {
    display: none;
    position: absolute;
    background-color: white;
    top: -10px;
    right: 10px;
    padding: 3px;
    border: 1px solid black;
  }
  pre.src:hover:before { display: inline;}
  /* Languages per Org manual */
  pre.src-asymptote:before { content: 'Asymptote'; }
  pre.src-awk:before { content: 'Awk'; }
  pre.src-C:before { content: 'C'; }
  /* pre.src-C++ doesn't work in CSS */
  pre.src-clojure:before { content: 'Clojure'; }
  pre.src-css:before { content: 'CSS'; }
  pre.src-D:before { content: 'D'; }
  pre.src-ditaa:before { content: 'ditaa'; }
  pre.src-dot:before { content: 'Graphviz'; }
  pre.src-calc:before { content: 'Emacs Calc'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-fortran:before { content: 'Fortran'; }
  pre.src-gnuplot:before { content: 'gnuplot'; }
  pre.src-haskell:before { content: 'Haskell'; }
  pre.src-hledger:before { content: 'hledger'; }
  pre.src-java:before { content: 'Java'; }
  pre.src-js:before { content: 'Javascript'; }
  pre.src-latex:before { content: 'LaTeX'; }
  pre.src-ledger:before { content: 'Ledger'; }
  pre.src-lisp:before { content: 'Lisp'; }
  pre.src-lilypond:before { content: 'Lilypond'; }
  pre.src-lua:before { content: 'Lua'; }
  pre.src-matlab:before { content: 'MATLAB'; }
  pre.src-mscgen:before { content: 'Mscgen'; }
  pre.src-ocaml:before { content: 'Objective Caml'; }
  pre.src-octave:before { content: 'Octave'; }
  pre.src-org:before { content: 'Org mode'; }
  pre.src-oz:before { content: 'OZ'; }
  pre.src-plantuml:before { content: 'Plantuml'; }
  pre.src-processing:before { content: 'Processing.js'; }
  pre.src-python:before { content: 'Python'; }
  pre.src-R:before { content: 'R'; }
  pre.src-ruby:before { content: 'Ruby'; }
  pre.src-sass:before { content: 'Sass'; }
  pre.src-scheme:before { content: 'Scheme'; }
  pre.src-screen:before { content: 'Gnu Screen'; }
  pre.src-sed:before { content: 'Sed'; }
  pre.src-sh:before { content: 'shell'; }
  pre.src-sql:before { content: 'SQL'; }
  pre.src-sqlite:before { content: 'SQLite'; }
  /* additional languages in org.el's org-babel-load-languages alist */
  pre.src-forth:before { content: 'Forth'; }
  pre.src-io:before { content: 'IO'; }
  pre.src-J:before { content: 'J'; }
  pre.src-makefile:before { content: 'Makefile'; }
  pre.src-maxima:before { content: 'Maxima'; }
  pre.src-perl:before { content: 'Perl'; }
  pre.src-picolisp:before { content: 'Pico Lisp'; }
  pre.src-scala:before { content: 'Scala'; }
  pre.src-shell:before { content: 'Shell Script'; }
  pre.src-ebnf2ps:before { content: 'ebfn2ps'; }
  /* additional language identifiers per "defun org-babel-execute"
       in ob-*.el */
  pre.src-cpp:before  { content: 'C++'; }
  pre.src-abc:before  { content: 'ABC'; }
  pre.src-coq:before  { content: 'Coq'; }
  pre.src-groovy:before  { content: 'Groovy'; }
  /* additional language identifiers from org-babel-shell-names in
     ob-shell.el: ob-shell is the only babel language using a lambda to put
     the execution function name together. */
  pre.src-bash:before  { content: 'bash'; }
  pre.src-csh:before  { content: 'csh'; }
  pre.src-ash:before  { content: 'ash'; }
  pre.src-dash:before  { content: 'dash'; }
  pre.src-ksh:before  { content: 'ksh'; }
  pre.src-mksh:before  { content: 'mksh'; }
  pre.src-posh:before  { content: 'posh'; }
  /* Additional Emacs modes also supported by the LaTeX listings package */
  pre.src-ada:before { content: 'Ada'; }
  pre.src-asm:before { content: 'Assembler'; }
  pre.src-caml:before { content: 'Caml'; }
  pre.src-delphi:before { content: 'Delphi'; }
  pre.src-html:before { content: 'HTML'; }
  pre.src-idl:before { content: 'IDL'; }
  pre.src-mercury:before { content: 'Mercury'; }
  pre.src-metapost:before { content: 'MetaPost'; }
  pre.src-modula-2:before { content: 'Modula-2'; }
  pre.src-pascal:before { content: 'Pascal'; }
  pre.src-ps:before { content: 'PostScript'; }
  pre.src-prolog:before { content: 'Prolog'; }
  pre.src-simula:before { content: 'Simula'; }
  pre.src-tcl:before { content: 'tcl'; }
  pre.src-tex:before { content: 'TeX'; }
  pre.src-plain-tex:before { content: 'Plain TeX'; }
  pre.src-verilog:before { content: 'Verilog'; }
  pre.src-vhdl:before { content: 'VHDL'; }
  pre.src-xml:before { content: 'XML'; }
  pre.src-nxml:before { content: 'XML'; }
  /* add a generic configuration mode; LaTeX export needs an additional
     (add-to-list 'org-latex-listings-langs '(conf " ")) in .emacs */
  pre.src-conf:before { content: 'Configuration File'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  .org-svg { width: 90%; }
  /*]]>*/-->
</style>
<style> P {text-align: justify} code, pre {font-family: monospace; font-size: 10pt; color: brown;} @media screen {BODY {margin: 10%} }</style>
<script type="text/javascript">
/*
@licstart  The following is the entire license notice for the
JavaScript code in this tag.

Copyright (C) 2012-2019 Free Software Foundation, Inc.

The JavaScript code in this tag is free software: you can
redistribute it and/or modify it under the terms of the GNU
General Public License (GNU GPL) as published by the Free Software
Foundation, either version 3 of the License, or (at your option)
any later version.  The code is distributed WITHOUT ANY WARRANTY;
without even the implied warranty of MERCHANTABILITY or FITNESS
FOR A PARTICULAR PURPOSE.  See the GNU GPL for more details.

As additional permission under GNU GPL version 3 section 7, you
may distribute non-source (e.g., minimized or compacted) forms of
that code without the copy of the GNU GPL normally required by
section 4, provided you include this license notice and a URL
through which recipients can access the Corresponding Source.


@licend  The above is the entire license notice
for the JavaScript code in this tag.
*/
<!--/*--><![CDATA[/*><!--*/
 function CodeHighlightOn(elem, id)
 {
   var target = document.getElementById(id);
   if(null != target) {
     elem.cacheClassElem = elem.className;
     elem.cacheClassTarget = target.className;
     target.className = "code-highlighted";
     elem.className   = "code-highlighted";
   }
 }
 function CodeHighlightOff(elem, id)
 {
   var target = document.getElementById(id);
   if(elem.cacheClassElem)
     elem.className = elem.cacheClassElem;
   if(elem.cacheClassTarget)
     target.className = elem.cacheClassTarget;
 }
/*]]>*///-->
</script>
</head>
<body>
<div id="preamble" class="status">
<a href="../../Top/"> CEG 7370</a>
</div>
<div id="content">
<h1 class="title">Hadoop and Alternatives</h1>
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#org46e2222">1. Word Count Example</a></li>
<li><a href="#orge9666a0">2. Slides</a></li>
<li><a href="#orgfdf9fb2">3. Hadoop Alternatives</a></li>
<li><a href="#org9805071">4. References</a></li>
</ul>
</div>
</div>

<div id="outline-container-org46e2222" class="outline-2">
<h2 id="org46e2222"><span class="section-number-2">1</span> Word Count Example</h2>
<div class="outline-text-2" id="text-1">
<ol class="org-ol">
<li>From <a href="http://wiki.apache.org/hadoop/WordCount">http://wiki.apache.org/hadoop/WordCount</a></li>

<li>WordCount program should: Read all of the text files in the input
directory (called inDir).  Discover all the words these files
collectively have.</li>

<li>WordCount program should output a text file, each line of which
contains a word, a tab, and the total count of how often that word
occured in the files read.</li>

<li>Do this using Hadoop.
<ol class="org-ol">
<li>Definitions of: word, occurence YKWIM</li>
<li>It is assumed that both input files and output file are stored
in Hadoop Distributed File System (HDFS)</li>
<li><code>hadoop jar hadoop-*-examples.jar wordcount [-m &lt;#maps&gt;] [-r
      &lt;#reducers&gt;] inDir outDir</code></li>
</ol></li>

<li>Mapper: Each mapper takes a line as input and breaks it into
words. It then emits a key/value pair of the word and 1.</li>

<li>Reducer: Each reducer sums the counts for each word and emits a
single key/value with the word and sum.</li>

<li><a href="./mapreduce-wordcount.C">./mapreduce-wordcount.C</a></li>
</ol>
</div>

<div id="outline-container-org5d4af2e" class="outline-3">
<h3 id="org5d4af2e"><span class="section-number-3">1.1</span> Commentary</h3>
<div class="outline-text-3" id="text-1-1">
<ol class="org-ol">
<li>"Hadoop is great for analyzing petabytes of data, but the tradeoff
is that it's expensive to have a team set up and maintain.  There
are companies like HortonWorks that specialize in enterprise Hadoop
installation to make it easier.  I think it will be interesting
over the next several years to see how the industry changes, and to
see how Hadoop adapts."</li>

<li>"" For all its benefits, Hadoop has its drawbacks. The actual
movement of data can be complex, and does not lend itself to
efficient execution. Discouraged with Hadoop’s heaviness, an online
advertising company developed and released as open source an
alternative called Cluster Map Reduce (CMR) that it says is
lighter, faster, and simpler to program.</li>

<li>Chitika CMR "" The mods worked well enough, but as the Chitika
developers dug into the Hadoop code, they were surprised by what
they found. “In particular, the path through Hadoop that data takes
is complex, going in and out of Java many times,” Chitika
developers wrote on their blog. “Basically, input data is read into
Java, then given to the mapper whose output is then consumed by
Java, then written to disk, where Java on another node reads it
back in to give it to the reducer, whose output is then consumed by
Java once again before it is written back to disk.”</li>
</ol>
</div>
</div>
</div>

<div id="outline-container-orge9666a0" class="outline-2">
<h2 id="orge9666a0"><span class="section-number-2">2</span> Slides</h2>
<div class="outline-text-2" id="text-2">
<ol class="org-ol">
<li><a href="./matetiHadoop.pptx">./matetiHadoop.pptx</a></li>
<li><a href="./MapReduce-UofI-2015.ppt">./MapReduce-UofI-2015.ppt</a></li>
<li><a href="./MapReduce-UToronto-2014.ppt">./MapReduce-UToronto-2014.ppt</a></li>
</ol>
</div>
</div>

<div id="outline-container-orgfdf9fb2" class="outline-2">
<h2 id="orgfdf9fb2"><span class="section-number-2">3</span> Hadoop Alternatives</h2>
<div class="outline-text-2" id="text-3">
<ol class="org-ol">
<li><a href="http://zillabyte.com/">http://zillabyte.com/</a></li>

<li>Stratosphere is now Apache
Flink. <a href="https://github.com/apache/incubator-flink">https://github.com/apache/incubator-flink</a> "" . "It has a
novel model that allows for more operators than just map and
reduce. (It also natively supports match, cross and more). It
additionally allows for arbitrary complex job graphs. So you can
combine these operators in any way you like. So you could have
three inputs, that are joined, reduced, mapped and reduced (by
another key). You can even write to as many outputs as you want.
Additionally, Stratosphere also supports iterative algorithms
(often needed for Data Mining/Machine Learning). Since this is
"natively" implemented into the system, Stratosphere does way
better on those jobs than traditional hadoop systems."  There is an
actively developed open source version of it on github:
<a href="https://github.com/dimalabs/ozone">https://github.com/dimalabs/ozone</a> Stratosphere also supports Scala.
Apache Flink is an open source system for fast and versatile data
analytics in clusters. Flink supports batch and streaming
analytics, in one system. Analytical programs can be written in
concise and elegant APIs in Java and Scala.</li>

<li><a href="http://spark.apache.org/">http://spark.apache.org/</a> "" Apache Spark is a fast and general engine
for large-scale data processing.  Applications can be written in
Scala, which is an very powerful and expressive functional
programming language (Stratosphere also supports Scala). It is
really fast on job setup, hence it is very suited for small and
medium sized data and ad-hoc evaluations.</li>

<li><a href="https://prestodb.io/">https://prestodb.io/</a> "" According to Facebook, Presto is a new
interactive query system that operates fast at petabyte scale that
is founded on a distributed SQL query engine optimized for ad-hoc
analysis at interactive speed. And like Spark, all processing is in
memory. Facebook recently open-sourced the code and the Presto
community can be found here.  Unlike Spark or Hadoop, Presto can
concurrently use a number of data stores as sources. All that is
needed are “connectors” that provide interfaces for metadata, data
locations, and data access. This obviates the need to move data
around in order to query it—a requirement that’s becoming critical
to many IT administrators. Simply plug the data source into Presto
and—presto!—it can be interactively queried in real
time. Connectors are currently available for Hadoop/Hive (Apache
and Cloudera distributions) and Cassandra. But one can imagine more
could be built for the enterprises’ existing data stores.</li>

<li><p>
<a href="https://github.com/addthis/hydra">https://github.com/addthis/hydra</a> "" It may not have the name
recognition or momentum of Hadoop. But Hydra, the distributed task
processing system first developed six years ago by the social
bookmarking service maker AddThis, is now available under an open
source Apache license, just like Hadoop. And according to Hydra’s
creator, the multi-headed platform is very good at some big data
tasks that the yellow pachyderm struggles with–namely real-time
processing of very big data sets.
</p>

<p>
"" Hydra is a big data storage and processing platform developed by
Matt Abrams and his colleagues at AddThis (formerly Clearspring),
the company that develops the Web server widgets that allow
visitors to easily share something via their Twitter, Facebook,
Pintrest, Google+, or Instagram accounts.
</p>

<p>
"" When AddThis started scaling up its business in the mid-2000s,
it got flooded with data about what users were sharing. The company
needed a scalable, distributed system that could deliver real-time
analysis of that data to its customers. Hadoop wasn’t a feasible
option at that time. So it built Hydra instead.
</p></li>
</ol>
</div>
</div>

<div id="outline-container-org9805071" class="outline-2">
<h2 id="org9805071"><span class="section-number-2">4</span> References</h2>
<div class="outline-text-2" id="text-4">
<ol class="org-ol">
<li><a href="http://wiki.apache.org/hadoop/WordCount">http://wiki.apache.org/hadoop/WordCount</a></li>
<li>dean-ghemawat-mapreduce-osdi04.pdf</li>
<li><a href="http://www.forbes.com/sites/johnwebster/2014/12/08/is-it-time-for-hadoop-alternatives/">http://www.forbes.com/sites/johnwebster/2014/12/08/is-it-time-for-hadoop-alternatives/</a></li>
<li><a href="http://www.fromdev.com/2015/03/hadoop-alternatives.html">http://www.fromdev.com/2015/03/hadoop-alternatives.html</a> 35+ Hadoop
Alternatives For Big Data</li>
</ol>
</div>
</div>
</div>
<div id="postamble" class="status">
<hr size=1>Copyright &copy; 2015 <a href="mailto:pmateti@wright.edu">pmateti@wright.edu</a> &bull; <a href="http://www.wright.edu/~pmateti"> www.wright.edu/~pmateti</a>  2015-03-13
</div>
</body>
</html>
